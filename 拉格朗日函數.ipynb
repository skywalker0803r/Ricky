{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "拉格朗日函數.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMKlfoba11ePqXxNP16WGaA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skywalker0803r/Ricky/blob/master/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%87%BD%E6%95%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oqbknETVMSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import warnings;warnings.simplefilter('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwnDa8dxO3iA",
        "colab_type": "text"
      },
      "source": [
        "# obj_function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRIPQC-uOoki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Φ(x,y,λ):\n",
        "  term_1 = (x**2)*y\n",
        "  term_2 = λ*(x**2+y**2-1)\n",
        "  return  term_1 + term_2 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXCfV9NrX-73",
        "colab_type": "text"
      },
      "source": [
        "## ANN method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6CeeICJP4aN",
        "colab_type": "text"
      },
      "source": [
        "# build net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7ewtsfaYBo0",
        "colab_type": "code",
        "outputId": "133b7bc9-413c-4c8b-9ecf-7f5b8208cb06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import torch\n",
        "from torch.nn import Linear,init,Sigmoid,Tanh\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "def build_net(input_shape,output_shape):\n",
        "  net = torch.nn.Sequential(\n",
        "      Linear(input_shape,output_shape),\n",
        "      Tanh(),\n",
        "      )\n",
        "  return net\n",
        "\n",
        "def init_weights(m):\n",
        "  if type(m) == Linear:\n",
        "    torch.nn.init.xavier_uniform(m.weight)\n",
        "    m.bias.data.fill_(0)\n",
        "\n",
        "net = build_net(1,3)\n",
        "net.apply(init_weights)\n",
        "net"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=1, out_features=3, bias=True)\n",
              "  (1): Tanh()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SRU5EA6PyVg",
        "colab_type": "text"
      },
      "source": [
        "# noise_iter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtrTNmMlPygG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a99c5d5d-5273-47a9-dacd-dcd9f96fa331"
      },
      "source": [
        "noise = torch.tensor(np.random.normal(size=(1,1)), dtype=torch.float)\n",
        "noise_datasets = torch.utils.data.TensorDataset(noise)\n",
        "noise_iter = torch.utils.data.DataLoader(noise_datasets,batch_size=1)\n",
        "noise_iter"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fba621af1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1398kqF9bOA9",
        "colab_type": "text"
      },
      "source": [
        "## optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnVVWBSCasMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(net.parameters(),lr=0.05)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f24SDHX1SW-j",
        "colab_type": "text"
      },
      "source": [
        "# obj"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRkHZIX6SXLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def obj_function(x,y,λ):\n",
        "  Loss = 0\n",
        "  N = len(x)\n",
        "  for xi,yi,λi in zip(x,y,λ):\n",
        "    Loss += Φ(xi,yi,λi)\n",
        "  return Loss/N"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr5OwvTacBcb",
        "colab_type": "text"
      },
      "source": [
        "# train loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4W4Rv1F6iOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net,noise_iter,obj_function,optimizer,num_epochs=50):\n",
        "  history = []\n",
        "  for epoch in range(num_epochs):\n",
        "    for noise in noise_iter:\n",
        "      z = net(noise[0])\n",
        "      x,y,λ = z[:,0],z[:,1],z[:,2]\n",
        "      loss = obj_function(x,y,λ)\n",
        "      loss.mean().backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "    # end one epochs\n",
        "    print(\"epochs {} loss {:.4f}\".format(epoch,loss.item()))\n",
        "    history.append(loss.item())\n",
        "  # end all epochs\n",
        "  plt.plot(np.array(history))\n",
        "  plt.title('train loss')\n",
        "  return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUcfuiKFQIow",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dd8261d7-56ee-44d0-a163-3f99c2847c46"
      },
      "source": [
        "train(net,noise_iter,obj_function,optimizer,200)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epochs 0 loss 0.1160\n",
            "epochs 1 loss 0.0202\n",
            "epochs 2 loss -0.0815\n",
            "epochs 3 loss -0.1827\n",
            "epochs 4 loss -0.2772\n",
            "epochs 5 loss -0.3603\n",
            "epochs 6 loss -0.4313\n",
            "epochs 7 loss -0.4932\n",
            "epochs 8 loss -0.5490\n",
            "epochs 9 loss -0.6001\n",
            "epochs 10 loss -0.6477\n",
            "epochs 11 loss -0.6928\n",
            "epochs 12 loss -0.7354\n",
            "epochs 13 loss -0.7743\n",
            "epochs 14 loss -0.8078\n",
            "epochs 15 loss -0.8345\n",
            "epochs 16 loss -0.8542\n",
            "epochs 17 loss -0.8683\n",
            "epochs 18 loss -0.8795\n",
            "epochs 19 loss -0.8906\n",
            "epochs 20 loss -0.9029\n",
            "epochs 21 loss -0.9154\n",
            "epochs 22 loss -0.9266\n",
            "epochs 23 loss -0.9353\n",
            "epochs 24 loss -0.9412\n",
            "epochs 25 loss -0.9451\n",
            "epochs 26 loss -0.9481\n",
            "epochs 27 loss -0.9512\n",
            "epochs 28 loss -0.9548\n",
            "epochs 29 loss -0.9587\n",
            "epochs 30 loss -0.9626\n",
            "epochs 31 loss -0.9660\n",
            "epochs 32 loss -0.9685\n",
            "epochs 33 loss -0.9702\n",
            "epochs 34 loss -0.9712\n",
            "epochs 35 loss -0.9722\n",
            "epochs 36 loss -0.9734\n",
            "epochs 37 loss -0.9750\n",
            "epochs 38 loss -0.9767\n",
            "epochs 39 loss -0.9781\n",
            "epochs 40 loss -0.9792\n",
            "epochs 41 loss -0.9799\n",
            "epochs 42 loss -0.9804\n",
            "epochs 43 loss -0.9809\n",
            "epochs 44 loss -0.9816\n",
            "epochs 45 loss -0.9823\n",
            "epochs 46 loss -0.9831\n",
            "epochs 47 loss -0.9837\n",
            "epochs 48 loss -0.9842\n",
            "epochs 49 loss -0.9846\n",
            "epochs 50 loss -0.9849\n",
            "epochs 51 loss -0.9853\n",
            "epochs 52 loss -0.9857\n",
            "epochs 53 loss -0.9861\n",
            "epochs 54 loss -0.9865\n",
            "epochs 55 loss -0.9868\n",
            "epochs 56 loss -0.9871\n",
            "epochs 57 loss -0.9873\n",
            "epochs 58 loss -0.9875\n",
            "epochs 59 loss -0.9878\n",
            "epochs 60 loss -0.9880\n",
            "epochs 61 loss -0.9883\n",
            "epochs 62 loss -0.9885\n",
            "epochs 63 loss -0.9887\n",
            "epochs 64 loss -0.9889\n",
            "epochs 65 loss -0.9891\n",
            "epochs 66 loss -0.9893\n",
            "epochs 67 loss -0.9894\n",
            "epochs 68 loss -0.9896\n",
            "epochs 69 loss -0.9898\n",
            "epochs 70 loss -0.9899\n",
            "epochs 71 loss -0.9901\n",
            "epochs 72 loss -0.9902\n",
            "epochs 73 loss -0.9904\n",
            "epochs 74 loss -0.9905\n",
            "epochs 75 loss -0.9906\n",
            "epochs 76 loss -0.9908\n",
            "epochs 77 loss -0.9909\n",
            "epochs 78 loss -0.9910\n",
            "epochs 79 loss -0.9911\n",
            "epochs 80 loss -0.9912\n",
            "epochs 81 loss -0.9913\n",
            "epochs 82 loss -0.9914\n",
            "epochs 83 loss -0.9916\n",
            "epochs 84 loss -0.9917\n",
            "epochs 85 loss -0.9918\n",
            "epochs 86 loss -0.9919\n",
            "epochs 87 loss -0.9919\n",
            "epochs 88 loss -0.9920\n",
            "epochs 89 loss -0.9921\n",
            "epochs 90 loss -0.9922\n",
            "epochs 91 loss -0.9923\n",
            "epochs 92 loss -0.9924\n",
            "epochs 93 loss -0.9925\n",
            "epochs 94 loss -0.9926\n",
            "epochs 95 loss -0.9926\n",
            "epochs 96 loss -0.9927\n",
            "epochs 97 loss -0.9928\n",
            "epochs 98 loss -0.9929\n",
            "epochs 99 loss -0.9930\n",
            "epochs 100 loss -0.9930\n",
            "epochs 101 loss -0.9931\n",
            "epochs 102 loss -0.9932\n",
            "epochs 103 loss -0.9932\n",
            "epochs 104 loss -0.9933\n",
            "epochs 105 loss -0.9934\n",
            "epochs 106 loss -0.9934\n",
            "epochs 107 loss -0.9935\n",
            "epochs 108 loss -0.9936\n",
            "epochs 109 loss -0.9936\n",
            "epochs 110 loss -0.9937\n",
            "epochs 111 loss -0.9938\n",
            "epochs 112 loss -0.9938\n",
            "epochs 113 loss -0.9939\n",
            "epochs 114 loss -0.9939\n",
            "epochs 115 loss -0.9940\n",
            "epochs 116 loss -0.9941\n",
            "epochs 117 loss -0.9941\n",
            "epochs 118 loss -0.9942\n",
            "epochs 119 loss -0.9942\n",
            "epochs 120 loss -0.9943\n",
            "epochs 121 loss -0.9943\n",
            "epochs 122 loss -0.9944\n",
            "epochs 123 loss -0.9944\n",
            "epochs 124 loss -0.9945\n",
            "epochs 125 loss -0.9945\n",
            "epochs 126 loss -0.9946\n",
            "epochs 127 loss -0.9946\n",
            "epochs 128 loss -0.9947\n",
            "epochs 129 loss -0.9947\n",
            "epochs 130 loss -0.9948\n",
            "epochs 131 loss -0.9948\n",
            "epochs 132 loss -0.9949\n",
            "epochs 133 loss -0.9949\n",
            "epochs 134 loss -0.9950\n",
            "epochs 135 loss -0.9950\n",
            "epochs 136 loss -0.9950\n",
            "epochs 137 loss -0.9951\n",
            "epochs 138 loss -0.9951\n",
            "epochs 139 loss -0.9952\n",
            "epochs 140 loss -0.9952\n",
            "epochs 141 loss -0.9952\n",
            "epochs 142 loss -0.9953\n",
            "epochs 143 loss -0.9953\n",
            "epochs 144 loss -0.9954\n",
            "epochs 145 loss -0.9954\n",
            "epochs 146 loss -0.9954\n",
            "epochs 147 loss -0.9955\n",
            "epochs 148 loss -0.9955\n",
            "epochs 149 loss -0.9955\n",
            "epochs 150 loss -0.9956\n",
            "epochs 151 loss -0.9956\n",
            "epochs 152 loss -0.9956\n",
            "epochs 153 loss -0.9957\n",
            "epochs 154 loss -0.9957\n",
            "epochs 155 loss -0.9957\n",
            "epochs 156 loss -0.9958\n",
            "epochs 157 loss -0.9958\n",
            "epochs 158 loss -0.9958\n",
            "epochs 159 loss -0.9959\n",
            "epochs 160 loss -0.9959\n",
            "epochs 161 loss -0.9959\n",
            "epochs 162 loss -0.9960\n",
            "epochs 163 loss -0.9960\n",
            "epochs 164 loss -0.9960\n",
            "epochs 165 loss -0.9961\n",
            "epochs 166 loss -0.9961\n",
            "epochs 167 loss -0.9961\n",
            "epochs 168 loss -0.9961\n",
            "epochs 169 loss -0.9962\n",
            "epochs 170 loss -0.9962\n",
            "epochs 171 loss -0.9962\n",
            "epochs 172 loss -0.9963\n",
            "epochs 173 loss -0.9963\n",
            "epochs 174 loss -0.9963\n",
            "epochs 175 loss -0.9963\n",
            "epochs 176 loss -0.9964\n",
            "epochs 177 loss -0.9964\n",
            "epochs 178 loss -0.9964\n",
            "epochs 179 loss -0.9964\n",
            "epochs 180 loss -0.9965\n",
            "epochs 181 loss -0.9965\n",
            "epochs 182 loss -0.9965\n",
            "epochs 183 loss -0.9965\n",
            "epochs 184 loss -0.9966\n",
            "epochs 185 loss -0.9966\n",
            "epochs 186 loss -0.9966\n",
            "epochs 187 loss -0.9966\n",
            "epochs 188 loss -0.9966\n",
            "epochs 189 loss -0.9967\n",
            "epochs 190 loss -0.9967\n",
            "epochs 191 loss -0.9967\n",
            "epochs 192 loss -0.9967\n",
            "epochs 193 loss -0.9968\n",
            "epochs 194 loss -0.9968\n",
            "epochs 195 loss -0.9968\n",
            "epochs 196 loss -0.9968\n",
            "epochs 197 loss -0.9968\n",
            "epochs 198 loss -0.9969\n",
            "epochs 199 loss -0.9969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=1, out_features=3, bias=True)\n",
              "  (1): Tanh()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJXZUx_YQIyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "cefbf5f1-9a74-4791-cfe4-7be809f4b97a"
      },
      "source": [
        "x,y,λ = net(noise[0]).detach().numpy()\n",
        "print(x,y,λ)\n",
        "print(round(x,2),round(y,2),round(λ,2))\n",
        "print(Φ(x,y,λ))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6.914139e-06 7.674098e-06 0.9969011\n",
            "0.0 0.0 1.0\n",
            "-0.9969010948071159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSzT-JINQI7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL9XV7Y6QI4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMgylu_pQI2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}